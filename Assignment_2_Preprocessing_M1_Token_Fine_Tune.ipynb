{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1d23b6c"
      },
      "source": [
        "# Assignment 2\n",
        "\n",
        "**Credits**: Andrea Galassi, Federico Ruggeri, Paolo Torroni\n",
        "\n",
        "**Keywords**: Transformers, Question Answering, CoQA"
      ],
      "id": "d1d23b6c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bd3f451b"
      },
      "source": [
        "## Deadlines\n",
        "\n",
        "* **December 11**, 2022: deadline for having assignments graded by January 11, 2023\n",
        "* **January 11**, 2023: deadline for half-point speed bonus per assignment\n",
        "* **After January 11**, 2023: assignments are still accepted, but there will be no speed bonus"
      ],
      "id": "bd3f451b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11ada8c8"
      },
      "source": [
        "## Overview"
      ],
      "id": "11ada8c8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47c07553"
      },
      "source": [
        "### Problem\n",
        "\n",
        "Question Answering (QA) on [CoQA](https://stanfordnlp.github.io/coqa/) dataset: a conversational QA dataset."
      ],
      "id": "47c07553"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4907f8d"
      },
      "source": [
        "### Task\n",
        "\n",
        "Given a question $Q$, a text passage $P$, the task is to generate the answer $A$.<br>\n",
        "$\\rightarrow A$ can be: (i) a free-form text or (ii) unanswerable;\n",
        "\n",
        "**Note**: an question $Q$ can refer to previous dialogue turns. <br>\n",
        "$\\rightarrow$ dialogue history $H$ may be a valuable input to provide the correct answer $A$."
      ],
      "id": "b4907f8d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b3760b5"
      },
      "source": [
        "### Models\n",
        "\n",
        "We are going to experiment with transformer-based models to define the following models:\n",
        "\n",
        "1.  $A = f_\\theta(Q, P)$\n",
        "\n",
        "2. $A = f_\\theta(Q, P, H)$\n",
        "\n",
        "where $f_\\theta$ is the transformer-based model we have to define with $\\theta$ parameters."
      ],
      "id": "9b3760b5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66cfee64"
      },
      "source": [
        "## The CoQA dataset"
      ],
      "id": "66cfee64"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "996fa650"
      },
      "source": [
        "<center>\n",
        "    <img src=\"https://drive.google.com/uc?export=view&id=16vrgyfoV42Z2AQX0QY7LHTfrgektEKKh\" width=\"750\"/>\n",
        "</center>"
      ],
      "id": "996fa650"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6e3e7d0"
      },
      "source": [
        "For detailed information about the dataset, feel free to check the original [paper](https://arxiv.org/pdf/1808.07042.pdf).\n",
        "\n"
      ],
      "id": "f6e3e7d0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfb6c37e"
      },
      "source": [
        "## Rationales\n",
        "\n",
        "Each QA pair is paired with a rationale $R$: it is a text span extracted from the given text passage $P$. <br>\n",
        "$\\rightarrow$ $R$ is not a requested output, but it can be used as an additional information at training time!"
      ],
      "id": "bfb6c37e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daa786e2"
      },
      "source": [
        "## Dataset Statistics\n",
        "\n",
        "* **127k** QA pairs.\n",
        "* **8k** conversations.\n",
        "* **7** diverse domains: Children's Stories, Literature, Mid/High School Exams, News, Wikipedia, Reddit, Science.\n",
        "* Average conversation length: **15 turns** (i.e., QA pairs).\n",
        "* Almost **half** of CoQA questions refer back to **conversational history**.\n",
        "* Only **train** and **validation** sets are available."
      ],
      "id": "daa786e2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d26d68b7"
      },
      "source": [
        "## Dataset snippet\n",
        "\n",
        "The dataset is stored in JSON format. Each dialogue is represented as follows:\n",
        "\n",
        "```\n",
        "{\n",
        "    \"source\": \"mctest\",\n",
        "    \"id\": \"3dr23u6we5exclen4th8uq9rb42tel\",\n",
        "    \"filename\": \"mc160.test.41\",\n",
        "    \"story\": \"Once upon a time, in a barn near a farm house, there lived a little white kitten named Cotton. \n",
        "    Cotton lived high up in a nice warm place above the barn where all of the farmer's horses slept. [...]\" % <-- $P$\n",
        "    \"questions\": [\n",
        "        {\n",
        "            \"input_text\": \"What color was Cotton?\",   % <-- $Q_1$\n",
        "            \"turn_id\": 1\n",
        "        },\n",
        "        {\n",
        "            \"input_text\": \"Where did she live?\",\n",
        "            \"turn_id\": 2\n",
        "        },\n",
        "        [...]\n",
        "    ],\n",
        "    \"answers\": [\n",
        "        {\n",
        "            \"span_start\": 59,   % <-- $R_1$ start index\n",
        "            \"spand_end\": 93,    % <-- $R_1$ end index\n",
        "            \"span_text\": \"a little white kitten named Cotton\",   % <-- $R_1$\n",
        "            \"input_text\" \"white\",   % <-- $A_1$      \n",
        "            \"turn_id\": 1\n",
        "        },\n",
        "        [...]\n",
        "    ]\n",
        "}\n",
        "```"
      ],
      "id": "d26d68b7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72c7558c"
      },
      "source": [
        "### Simplifications\n",
        "\n",
        "Each dialogue also contains an additional field ```additional_answers```. For simplicity, we **ignore** this field and only consider one groundtruth answer $A$ and text rationale $R$.\n",
        "\n",
        "CoQA only contains 1.3% of unanswerable questions. For simplicity, we **ignore** those QA pairs."
      ],
      "id": "72c7558c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e01cdad7"
      },
      "source": [
        "## [Task 1] Remove unaswerable QA pairs\n",
        "\n",
        "Write your own script to remove unaswerable QA pairs from both train and validation sets."
      ],
      "id": "e01cdad7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6643e14"
      },
      "source": [
        "## Dataset Download\n"
      ],
      "id": "f6643e14"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "358bac70"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import urllib.request\n",
        "from tqdm import tqdm\n",
        "\n",
        "class DownloadProgressBar(tqdm):\n",
        "    def update_to(self, b=1, bsize=1, tsize=None):\n",
        "        if tsize is not None:\n",
        "            self.total = tsize\n",
        "        self.update(b * bsize - self.n)\n",
        "        \n",
        "def download_url(url, output_path):\n",
        "    with DownloadProgressBar(unit='B', unit_scale=True,\n",
        "                             miniters=1, desc=url.split('/')[-1]) as t:\n",
        "        urllib.request.urlretrieve(url, filename=output_path, reporthook=t.update_to)\n",
        "\n",
        "def download_data(data_path, url_path, suffix):    \n",
        "    if not os.path.exists(data_path):\n",
        "        os.makedirs(data_path)\n",
        "        \n",
        "    data_path = os.path.join(data_path, f'{suffix}.json')\n",
        "\n",
        "    if not os.path.exists(data_path):\n",
        "        print(f\"Downloading CoQA {suffix} data split... (it may take a while)\")\n",
        "        download_url(url=url_path, output_path=data_path)\n",
        "        print(\"Download completed!\")"
      ],
      "id": "358bac70"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5f6ab3ff"
      },
      "outputs": [],
      "source": [
        "# Train data\n",
        "train_url = \"https://nlp.stanford.edu/data/coqa/coqa-train-v1.0.json\"\n",
        "download_data(data_path='coqa', url_path=train_url, suffix='train')\n",
        "\n",
        "# Test data\n",
        "test_url = \"https://nlp.stanford.edu/data/coqa/coqa-dev-v1.0.json\"\n",
        "download_data(data_path='coqa', url_path=test_url, suffix='test')  # <-- Why test? See next slides for an answer!"
      ],
      "id": "5f6ab3ff"
    },
    {
      "cell_type": "code",
      "source": [
        "# Install transformers package\n",
        "!pip install transformers\n",
        "\n",
        "# Import libraries\n",
        "import json\n",
        "import pandas as pd\n",
        "import random\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import AdamW"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L79zPUWxljn7",
        "outputId": "f15e15f7-724b-4742-f98d-aea926bfc7e7"
      },
      "id": "L79zPUWxljn7",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define device as GPU if available\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "# initialize number of epochs\n",
        "epochs = 1"
      ],
      "metadata": {
        "id": "jJP_-Gbj1igj"
      },
      "id": "jJP_-Gbj1igj",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOy50nGAx_O-",
        "outputId": "732717ce-644c-4f6b-8b9d-51af4fefa3ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training and validation unaswerable stats:\n",
            "Training and validation stories with all unaswerable questions are: 6 vs. a total number of stories of 7199 : 0.08  %\n",
            "Test q/a pairs with unaswerable questions are: 1362 vs. a total number of q/a pairs of 108647 : 1.25  %\n",
            "\n",
            "Test unaswerable stats:\n",
            "Test stories with all unaswerable questions are: 2 vs. a total number of stories of 500 : 0.4  %\n",
            "Test q/a pairs with unaswerable questions are: 92 vs. a total number of q/a pairs of 7421 : 1.24  %\n",
            "\n",
            "Please note: the requirement is to split trainig and validation at story level (not q/a)\n",
            "therefore counts at story level will be used to compute properly the 80-20 split\n",
            "While the checks required to exclude unaswerable q/a pairs will be done at each q/a pairs level\n"
          ]
        }
      ],
      "source": [
        "# Store unknown IDs in a list to exclude them during the creation of the training, validation and test datasets\n",
        "# Training\n",
        "train_data_json = open('./coqa/train.json')\n",
        "train_data = json.load(train_data_json)\n",
        "train_val_tot = len(train_data['data'])\n",
        "train_val_tot_q = 0\n",
        "train_val_cnt = 0      \n",
        "train_val_cnt_q = 0\n",
        "idx_un_train = []\n",
        "idx_un_test = []\n",
        "\n",
        "for idx in range(train_val_tot):\n",
        "    all_unasnwered = True\n",
        "    for x in range(0,len(train_data['data'][idx]['questions'])): # If at least one answer is answerable store it in the training lists\n",
        "      train_val_tot_q += 1\n",
        "      if train_data['data'][idx]['answers'][x]['span_text'] != 'unknown':\n",
        "        all_unasnwered = False\n",
        "        train_val_cnt_q += 1      \n",
        "    if all_unasnwered:\n",
        "      idx_un_train.append(idx) # store the story idx so to exclude it from further processing and from the 80-20 split computation\n",
        "    else: # if the story at least one answerable question store the idx in the training story list     \n",
        "      train_val_cnt += 1\n",
        "      \n",
        "cnt_un_train_val = train_val_tot - train_val_cnt\n",
        "\n",
        "percentage = round((100 * (cnt_un_train_val / train_val_tot)),2)\n",
        "percentage_q = round((100 * ((train_val_tot_q - train_val_cnt_q) / train_val_tot_q)),2)\n",
        "\n",
        "print(\"Training and validation unaswerable stats:\")\n",
        "print(\"Training and validation stories with all unaswerable questions are:\",cnt_un_train_val,\"vs. a total number of stories of\",train_val_tot,\":\",percentage,\" %\")\n",
        "print(\"Test q/a pairs with unaswerable questions are:\",(train_val_tot_q - train_val_cnt_q),\"vs. a total number of q/a pairs of\",train_val_tot_q,\":\",percentage_q,\" %\")\n",
        "\n",
        "# Test\n",
        "test_data_json = open('./coqa/test.json')\n",
        "test_data = json.load(test_data_json)\n",
        "test_tot = len(test_data['data'])\n",
        "test_cnt = 0      \n",
        "test_cnt_q = 0\n",
        "test_tot_q = 0      \n",
        "\n",
        "for idx in range(0,len(test_data['data'])):\n",
        "    all_unasnwered = True\n",
        "    for x in range(0,len(train_data['data'][idx]['questions'])): # If at least one answer is answerable store it in the training lists\n",
        "      test_tot_q += 1\n",
        "      if train_data['data'][idx]['answers'][x]['span_text'] != 'unknown':\n",
        "        all_unasnwered = False\n",
        "        test_cnt_q += 1      \n",
        "    if all_unasnwered:\n",
        "      idx_un_test.append(idx) # store the story idx so to exclude it from further processing and from the 80-20 split computation\n",
        "    else: # if the story at least one answerable question store the idx in the training story list     \n",
        "      test_cnt += 1\n",
        "      \n",
        "cnt_un_test = test_tot - test_cnt\n",
        "\n",
        "percentage = round((100 * (cnt_un_test / test_tot)),2)\n",
        "percentage_q = round((100 * ((test_tot_q - test_cnt_q) / test_tot_q)),2)\n",
        "\n",
        "print(\"\\nTest unaswerable stats:\")\n",
        "print(\"Test stories with all unaswerable questions are:\",cnt_un_test,\"vs. a total number of stories of\",test_tot,\":\",percentage,\" %\")\n",
        "print(\"Test q/a pairs with unaswerable questions are:\",(test_tot_q - test_cnt_q),\"vs. a total number of q/a pairs of\",test_tot_q,\":\",percentage_q,\" %\")\n",
        "\n",
        "print(\"\\nPlease note: the requirement is to split trainig and validation at story level (not q/a)\")\n",
        "print(\"therefore counts at story level will be used to compute properly the 80-20 split\")\n",
        "print(\"While the checks required to exclude unaswerable q/a pairs will be done at each q/a pairs level\")"
      ],
      "id": "pOy50nGAx_O-"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40e42311"
      },
      "source": [
        "#### Data Inspection\n",
        "\n",
        "Spend some time in checking accurately the dataset format and how to retrieve the tasks' inputs and outputs!"
      ],
      "id": "40e42311"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 933
        },
        "id": "vLiH4tnVpGDm",
        "outputId": "a2ff5f66-fd13-43e1-ff04-f7f4161ed67b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Dataframe shape\n",
            " (7199, 2)\n",
            "\n",
            "Example of one dataframe row:\n",
            " version                                                    1\n",
            "data       {'source': 'gutenberg', 'id': '3bdcf01ogxu7zdn...\n",
            "Name: 2, dtype: object\n",
            "\n",
            "Data dictionary keys\n",
            " dict_keys(['source', 'id', 'filename', 'story', 'questions', 'answers', 'name']) \n",
            "\n",
            "\n",
            "Story\n",
            " CHAPTER VII. THE DAUGHTER OF WITHERSTEEN \n",
            "\n",
            "\"Lassiter, will you be my rider?\" Jane had asked him. \n",
            "\n",
            "\"I reckon so,\" he had replied. \n",
            "\n",
            "Few as the words were, Jane knew how infinitely much they implied. She wanted him to take charge of her cattle and horse and ranges, and save them if that were possible. Yet, though she could not have spoken aloud all she meant, she was perfectly honest with herself. Whatever the price to be paid, she must keep Lassiter close to her; she must shield from him the man who had led Milly Erne to Cottonwoods. In her fear she so controlled her mind that she did not whisper this Mormon's name to her own soul, she did not even think it. Besides, beyond this thing she regarded as a sacred obligation thrust upon her, was the need of a helper, of a friend, of a champion in this critical time. If she could rule this gun-man, as Venters had called him, if she could even keep him from shedding blood, what strategy to play his flame and his presence against the game of oppression her churchmen were waging against her? Never would she forget the effect on Tull and his men when Venters shouted Lassiter's name. If she could not wholly control Lassiter, then what she could do might put off the fatal day. \n",
            "\n",
            "One of her safe racers was a dark bay, and she called him Bells because of the way he struck his iron shoes on the stones. When Jerd led out this slender, beautifully built horse Lassiter suddenly became all eyes. A rider's love of a thoroughbred shone in them. Round and round Bells he walked, plainly weakening all the time in his determination not to take one of Jane's favorite racers.  \n",
            "\n",
            "\n",
            "Questions\n",
            " [{'input_text': 'What did Venters call Lassiter?', 'turn_id': 1}, {'input_text': 'Who asked Lassiter to be their rider?', 'turn_id': 2}, {'input_text': 'Did he agree?', 'turn_id': 3}, {'input_text': 'Why did she ask him?', 'turn_id': 4}, {'input_text': 'Did she tell him as much?', 'turn_id': 5}, {'input_text': 'What was she willing to give up?', 'turn_id': 6}, {'input_text': 'Where was Milly led to?', 'turn_id': 7}, {'input_text': 'Who took her there?', 'turn_id': 8}, {'input_text': 'Whose name would Jane not speak?', 'turn_id': 9}, {'input_text': 'Did she allow herself to even think it?', 'turn_id': 10}, {'input_text': 'What was Jane hoping Lassiter would become to her?', 'turn_id': 11}, {'input_text': 'Who was oppressing her?', 'turn_id': 12}, {'input_text': 'What was she hoping she could keep from happening to him?', 'turn_id': 13}, {'input_text': \"Who had shouted Lassiter's name?\", 'turn_id': 14}, {'input_text': 'Who did that affect?', 'turn_id': 15}, {'input_text': 'Did Jane think she could control Lassiter?', 'turn_id': 16}, {'input_text': 'Who is Bells?', 'turn_id': 17}, {'input_text': 'How did he get his name?', 'turn_id': 18}, {'input_text': 'Was Lassiter impressed with the horse?', 'turn_id': 19}, {'input_text': 'Did he want to take him for himself?', 'turn_id': 20}] \n",
            "\n",
            "\n",
            "Answers\n",
            " [{'span_start': 841, 'span_end': 880, 'span_text': 'this gun-man, as Venters had called him', 'input_text': 'gun-man', 'turn_id': 1}, {'span_start': 43, 'span_end': 97, 'span_text': '\"Lassiter, will you be my rider?\" Jane had asked him. ', 'input_text': 'Jane', 'turn_id': 2}, {'span_start': 99, 'span_end': 129, 'span_text': '\"I reckon so,\" he had replied.', 'input_text': 'Yes', 'turn_id': 3}, {'span_start': 199, 'span_end': 301, 'span_text': 'She wanted him to take charge of her cattle and horse and ranges, and save them if that were possible.', 'input_text': 'to take charge of her cattle and horse and ranges, and save them', 'turn_id': 4}, {'span_start': 307, 'span_end': 360, 'span_text': 'though she could not have spoken aloud all she meant,', 'input_text': 'No', 'turn_id': 5}, {'span_start': 400, 'span_end': 429, 'span_text': 'Whatever the price to be paid', 'input_text': 'Whatever the price to be paid', 'turn_id': 6}, {'span_start': 509, 'span_end': 538, 'span_text': 'led Milly Erne to Cottonwoods', 'input_text': 'Cottonwoods', 'turn_id': 7}, {'span_start': 493, 'span_end': 538, 'span_text': 'the man who had led Milly Erne to Cottonwoods', 'input_text': 'A man', 'turn_id': 8}, {'span_start': 604, 'span_end': 622, 'span_text': \"this Mormon's name\", 'input_text': \"this Mormon's name\", 'turn_id': 9}, {'span_start': 640, 'span_end': 666, 'span_text': 'she did not even think it.', 'input_text': 'No', 'turn_id': 10}, {'span_start': 751, 'span_end': 798, 'span_text': 'the need of a helper, of a friend, of a champio', 'input_text': 'a helper, of a friend, of a champion', 'turn_id': 11}, {'span_start': 991, 'span_end': 1047, 'span_text': 'game of oppression her churchmen were waging against her', 'input_text': 'her churchmen', 'turn_id': 12}, {'span_start': 885, 'span_end': 928, 'span_text': 'she could even keep him from shedding blood', 'input_text': 'shedding blood', 'turn_id': 13}, {'span_start': 1108, 'span_end': 1140, 'span_text': \"Venters shouted Lassiter's name.\", 'input_text': 'Venters', 'turn_id': 14}, {'span_start': 1071, 'span_end': 1140, 'span_text': \" the effect on Tull and his men when Venters shouted Lassiter's name.\", 'input_text': 'Tull and his men', 'turn_id': 15}, {'span_start': 1141, 'span_end': 1205, 'span_text': 'If she could not wholly control Lassiter, then what she could do', 'input_text': 'No', 'turn_id': 16}, {'span_start': 1237, 'span_end': 1300, 'span_text': 'One of her safe racers was a dark bay, and she called him Bells', 'input_text': 'One of her safe racers', 'turn_id': 17}, {'span_start': 1280, 'span_end': 1360, 'span_text': 'she called him Bells because of the way he struck his iron shoes on the stones. ', 'input_text': 'because of the way he struck his iron shoes on the stones.', 'turn_id': 18}, {'span_start': 1360, 'span_end': 1450, 'span_text': 'When Jerd led out this slender, beautifully built horse Lassiter suddenly became all eyes.', 'input_text': 'Yes', 'turn_id': 19}, {'span_start': 1532, 'span_end': 1625, 'span_text': \"plainly weakening all the time in his determination not to take one of Jane's favorite racers\", 'input_text': 'Yes', 'turn_id': 20}] \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   version                                               data\n",
              "0        1  {'source': 'wikipedia', 'id': '3zotghdk5ibi9ce...\n",
              "1        1  {'source': 'cnn', 'id': '3wj1oxy92agboo5nlq4r7...\n",
              "2        1  {'source': 'gutenberg', 'id': '3bdcf01ogxu7zdn...\n",
              "3        1  {'source': 'cnn', 'id': '3ewijtffvo7wwchw6rtya...\n",
              "4        1  {'source': 'gutenberg', 'id': '3urfvvm165iantk...\n",
              "5        1  {'source': 'race', 'id': '3ftf2t8wlri896r0rn6x...\n",
              "6        1  {'source': 'cnn', 'id': '3qemnnsb2xz5mh3gvv3nj...\n",
              "7        1  {'source': 'race', 'id': '369j354ofdapu1z2ebz3...\n",
              "8        1  {'source': 'race', 'id': '3v0z7ywsiy0kux6wg4mm...\n",
              "9        1  {'source': 'wikipedia', 'id': '3v5q80fxixr0io4..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-41423778-b69a-4376-b04f-e129d07856f2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>version</th>\n",
              "      <th>data</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>{'source': 'wikipedia', 'id': '3zotghdk5ibi9ce...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>{'source': 'cnn', 'id': '3wj1oxy92agboo5nlq4r7...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>{'source': 'gutenberg', 'id': '3bdcf01ogxu7zdn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>{'source': 'cnn', 'id': '3ewijtffvo7wwchw6rtya...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>{'source': 'gutenberg', 'id': '3urfvvm165iantk...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>{'source': 'race', 'id': '3ftf2t8wlri896r0rn6x...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>{'source': 'cnn', 'id': '3qemnnsb2xz5mh3gvv3nj...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>{'source': 'race', 'id': '369j354ofdapu1z2ebz3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>{'source': 'race', 'id': '3v0z7ywsiy0kux6wg4mm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>{'source': 'wikipedia', 'id': '3v5q80fxixr0io4...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-41423778-b69a-4376-b04f-e129d07856f2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-41423778-b69a-4376-b04f-e129d07856f2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-41423778-b69a-4376-b04f-e129d07856f2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df_train_mockup = pd.read_json('./coqa/train.json')\n",
        "print(\"Training Dataframe shape\\n\",df_train_mockup.shape)\n",
        "print(\"\\nExample of one dataframe row:\\n\",df_train_mockup.iloc[2])\n",
        "# Focusing on 'data' column\n",
        "print(\"\\nData dictionary keys\\n\",df_train_mockup['data'].iloc[2].keys(),'\\n')\n",
        "print(\"\\nStory\\n\",df_train_mockup['data'].iloc[2]['story'],'\\n')\n",
        "print(\"\\nQuestions\\n\",df_train_mockup['data'].iloc[2]['questions'],'\\n')\n",
        "print(\"\\nAnswers\\n\",df_train_mockup['data'].iloc[2]['answers'],'\\n')\n",
        "df_train_mockup.head(10)"
      ],
      "id": "vLiH4tnVpGDm"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f57334e0"
      },
      "source": [
        "## [Task 2] Train, Validation and Test splits\n",
        "\n",
        "CoQA only provides a train and validation set since the test set is hidden for evaluation purposes.\n",
        "\n",
        "We'll consider the provided validation set as a test set. <br>\n",
        "$\\rightarrow$ Write your own script to:\n",
        "* Split the train data in train and validation splits (80% train and 20% val)\n",
        "* Perform splits such that a dialogue appears in one split only! (i.e., split at dialogue level)\n",
        "* Perform splitting using the following seed for reproducibility: 42\n",
        "\n",
        "#### Reproducibility Memo\n",
        "\n",
        "Check back tutorial 2 on how to fix a specific random seed for reproducibility!"
      ],
      "id": "f57334e0"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "u4flu4pyhfpn"
      },
      "outputs": [],
      "source": [
        "# Generate training and validation dialogues and corresponding Q/A dataset splits accordingly to 80/20 ratio\n",
        "# excluding dialogues with unaswered questions\n",
        "# To avoid introducing bias across epochs, select randomly the dialogues\n",
        "# Selection starts from stories, and then corresponding Q/A are selected to ensure the split between training and validation is done at dialogue level\n",
        "\n",
        "# Initialization\n",
        "random.seed(42)\n",
        "train_split = 0.8\n",
        "val_split = 1-train_split\n",
        "train_idx = []\n",
        "train_ukn = []\n",
        "train_id = []\n",
        "train_story = []\n",
        "train_question = []\n",
        "train_answer_start = []\n",
        "train_answer_end = []\n",
        "val_id = []\n",
        "val_story = []\n",
        "val_question = []\n",
        "val_answer_start = []\n",
        "val_answer_end = []\n",
        "test_id = []\n",
        "test_story = []\n",
        "test_question = []\n",
        "test_answer_start = []\n",
        "test_answer_end = []\n",
        "train_qa = {}\n",
        "train_val_tot = len(train_data['data'])\n",
        "train_val_net_tot = train_val_tot - cnt_un_train_val\n",
        "train_rec_tot = int(train_split*train_val_net_tot)\n",
        "train_cnt = 0\n",
        "train_cnt_q = 0\n",
        "val_cnt = 0\n",
        "val_cnt_q = 0\n",
        "test_cnt = 0\n",
        "test_cnt_q = 0\n",
        "\n",
        "# Iterate over training data selecting 80% of the dialogues randomly and store them in the training story dictiornary provided \n",
        "# they do not contain unaswerable questions and that are not already present.\n",
        "# Once a dialogue is stored in the stories dictionary insert the corresponding questions in the QA training dictionary.\n",
        "# Q/A are linked to the corresponding dialogues, storing the stories ID.\n",
        "\n",
        "# Training\n",
        "end_of_train = False\n",
        "while not end_of_train: \n",
        "  idx = random.randint(0,train_val_tot) # Select a random story from training\n",
        "  if ((idx not in idx_un_train) and (idx not in train_idx)): # Check the story is not already in the training set and that it does not contain all unaswerable questions.\n",
        "    all_unasnwered = True\n",
        "    for x in range(0,len(train_data['data'][idx]['questions'])): # If at least one answer is answerable store it in the training lists\n",
        "      if train_data['data'][idx]['answers'][x]['span_text'] != 'unknown':\n",
        "        train_id.append(train_data['data'][idx]['id'])\n",
        "        train_story.append(train_data['data'][idx]['story'])\n",
        "        train_question.append(train_data['data'][idx]['questions'][x]['input_text'])\n",
        "        train_answer_start.append(train_data['data'][idx]['answers'][x]['span_start'])\n",
        "        train_answer_end.append(train_data['data'][idx]['answers'][x]['span_end'])\n",
        "        all_unasnwered = False\n",
        "        train_cnt_q += 1      \n",
        "    if not all_unasnwered: # if the story at least one answerable question store the idx in the training story list     \n",
        "      train_cnt += 1\n",
        "      train_idx.append(idx)\n",
        "  if train_cnt == train_rec_tot: end_of_train = True # Reached the target stories for training, end loop\n",
        "\n",
        "# Validation\n",
        "for idx in range(0,train_val_tot): # iterate over all stories  \n",
        "  if ((idx not in idx_un_train) and (idx not in train_idx)): # if the story has not been already marked as unanswerable or in training\n",
        "    all_unasnwered = True\n",
        "    for x in range(0,len(train_data['data'][idx]['questions'])): # If at least one answer is answerable store it in the training lists\n",
        "      if train_data['data'][idx]['answers'][x]['span_text'] != 'unknown':\n",
        "        val_id.append(train_data['data'][idx]['id'])\n",
        "        val_story.append(train_data['data'][idx]['story'])\n",
        "        val_question.append(train_data['data'][idx]['questions'][x]['input_text'])\n",
        "        val_answer_start.append(train_data['data'][idx]['answers'][x]['span_start'])\n",
        "        val_answer_end.append(train_data['data'][idx]['answers'][x]['span_end'])\n",
        "        all_unasnwered = False\n",
        "        val_cnt_q += 1      \n",
        "    if not all_unasnwered: # if the story at least one answerable question store the idx in the training story list\n",
        "      val_cnt += 1\n",
        "\n",
        "# Test\n",
        "test_tot = len(test_data['data'])\n",
        "\n",
        "for idx in range(0,test_tot): # iterate over all test stories\n",
        "  if (idx not in idx_un_test): # if the story has not been already marked as unanswerable\n",
        "    all_unasnwered = True\n",
        "    for x in range(0,len(train_data['data'][idx]['questions'])): # If at least one answer is answerable store it in the test lists\n",
        "      if train_data['data'][idx]['answers'][x]['span_text'] != 'unknown':\n",
        "        test_id.append(train_data['data'][idx]['id'])\n",
        "        test_story.append(train_data['data'][idx]['story'])\n",
        "        test_question.append(train_data['data'][idx]['questions'][x]['input_text'])\n",
        "        test_answer_start.append(train_data['data'][idx]['answers'][x]['span_start'])\n",
        "        test_answer_end.append(train_data['data'][idx]['answers'][x]['span_end'])\n",
        "        test_cnt_q += 1\n",
        "        all_unasnwered = False\n",
        "    if not all_unasnwered: # if the story at least one answerable question store the idx in the training story list\n",
        "      test_cnt += 1"
      ],
      "id": "u4flu4pyhfpn"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KRcdntD4yBJ",
        "outputId": "00804390-9aa5-4a5f-c2a3-0ff974890816"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analysis of the training data\n",
            "TOT: Total dialogues in the original training repository:  7199\n",
            "UKN: Unaswerable dialogues in the original training repository:  6\n",
            "TOT - UKN: Dialogues to be split between training and validaton:  7193\n",
            "\n",
            "Training dataset\n",
            "Expected training dialogues  80.0 % of (TOT - UKN): 5754\n",
            "Actual training dialogues:  5754\n",
            "Actual training q/a pairs:  86032\n",
            "\n",
            "Validation dataset\n",
            "Expected validation dialogues:  1439\n",
            "Actual validation dialogues 1439\n",
            "Actual validation q/a pairs 21253\n",
            "\n",
            "Test dataset\n",
            "TOT: Total dialogues in the original test repository:  500\n",
            "UKN: Unaswerable dialogues in the original training repository:  2\n",
            "TOT - UKN: Dialogues to be split between training and validaton:  498\n",
            "Expected test dialogues (TOT - UKN): 498\n",
            "Actual test dialogues:  498\n",
            "Actual test q/a pairs:  7329\n"
          ]
        }
      ],
      "source": [
        "# Analysis of the training data\n",
        "print(\"Analysis of the training data\")\n",
        "print(\"TOT: Total dialogues in the original training repository: \",train_val_tot)\n",
        "print(\"UKN: Unaswerable dialogues in the original training repository: \",cnt_un_train_val)\n",
        "print(\"TOT - UKN: Dialogues to be split between training and validaton: \",(train_val_tot-cnt_un_train_val))\n",
        "# Training dataset\n",
        "print(\"\\nTraining dataset\")\n",
        "print(\"Expected training dialogues \",round((train_split*100),0),\"% of (TOT - UKN):\",int(train_split*train_val_net_tot))\n",
        "print(\"Actual training dialogues: \",train_cnt)\n",
        "print(\"Actual training q/a pairs: \",train_cnt_q)\n",
        "# Validation dataset\n",
        "print(\"\\nValidation dataset\")\n",
        "print(\"Expected validation dialogues: \",(train_val_tot-cnt_un_train_val-train_cnt))\n",
        "print(\"Actual validation dialogues\",val_cnt)\n",
        "print(\"Actual validation q/a pairs\",val_cnt_q)\n",
        "\n",
        "# Analysis of the test data\n",
        "print(\"\\nTest dataset\")\n",
        "print(\"TOT: Total dialogues in the original test repository: \",test_tot)\n",
        "print(\"UKN: Unaswerable dialogues in the original training repository: \",cnt_un_test)\n",
        "print(\"TOT - UKN: Dialogues to be split between training and validaton: \",(test_tot-cnt_un_test))\n",
        "# Test dataset\n",
        "print(\"Expected test dialogues (TOT - UKN):\",(test_tot-cnt_un_test))\n",
        "print(\"Actual test dialogues: \",test_cnt)\n",
        "print(\"Actual test q/a pairs: \",test_cnt_q)"
      ],
      "id": "2KRcdntD4yBJ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "230a21de"
      },
      "source": [
        "## [Task 3] Model definition\n",
        "\n",
        "Write your own script to define the following transformer-based models from [huggingface](https://HuggingFace.co/).\n",
        "\n",
        "* [M1] DistilRoBERTa (distilberta-base)\n",
        "* [M2] BERTTiny (bert-tiny)\n",
        "\n",
        "**Note**: Remember to install the ```transformers``` python package!\n",
        "\n",
        "**Note**: We consider small transformer models for computational reasons!"
      ],
      "id": "230a21de"
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization function\n",
        "def tokenization(tokenizer,story,question,answer_start,answer_end):\n",
        "  # Initialization\n",
        "  answer_start_token = []\n",
        "  answer_end_token = []\n",
        "  story_clean_none = []\n",
        "  question_clean_none = []\n",
        "  answer_start_token_clean_none = []\n",
        "  answer_end_token_clean_none = []\n",
        "  idx_none = []\n",
        "\n",
        "  # Tokenization of stories and questions \n",
        "  encodings = tokenizer(story,question,truncation=True,padding=True)\n",
        "\n",
        "  # Translate answer span start/end pointers from story text indexes to token embedding indexes \n",
        "  # managing cases where answer start/end are pointing to 'blanks'\n",
        "  for i in range(len(answer_start)):\n",
        "    answer_start_token.append(encodings.char_to_token(i,answer_start[i]))\n",
        "    if answer_start_token[-1] is None:\n",
        "      answer_start_token[-1] = encodings.char_to_token(i,answer_start[i]+1)\n",
        "    if answer_start_token[-1] is None:\n",
        "      answer_start_token[-1] = encodings.char_to_token(i,answer_start[i]+2)\n",
        "  for i in range(len(answer_end)):\n",
        "    answer_end_token.append(encodings.char_to_token(i,answer_end[i]))\n",
        "    if answer_end_token[-1] is None:\n",
        "      answer_end_token[-1] = encodings.char_to_token(i,answer_end[i]+1)\n",
        "    if answer_end_token[-1] is None:\n",
        "      answer_end_token[-1] = encodings.char_to_token(i,answer_end[i]+2)\n",
        "  \n",
        "  # Create lists skippng question/answer pairs where answer span start or span end to tokens are 'None' \n",
        "  cnt = 0\n",
        "  for i in range(len(answer_start_token)):\n",
        "    if answer_start_token[i] is None:\n",
        "      idx_none.append(i)\n",
        "  cnt = 0\n",
        "  for i in range(len(answer_end_token)):\n",
        "    if answer_end_token[i] is None:\n",
        "      idx_none.append(i)\n",
        "\n",
        "  for i in range(len(story)):\n",
        "    if i not in idx_none:\n",
        "      story_clean_none.append(story[i])\n",
        "      question_clean_none.append(question[i])\n",
        "      answer_start_token_clean_none.append(answer_start_token[i])\n",
        "      answer_end_token_clean_none.append(answer_end_token[i])\n",
        "  \n",
        "  # Tokenization of the cleaned up lists and adding token based start and end position\n",
        "  encodings=tokenizer(story_clean_none,question_clean_none,truncation=True,padding=True)\n",
        "  encodings.update({'start_positions':answer_start_token_clean_none,'end_positions':answer_end_token_clean_none})\n",
        "  \n",
        "  print(\"Q/A pairs tokenized\",len(story_clean_none))\n",
        "  return(encodings)\n"
      ],
      "metadata": {
        "id": "S0aMsAL9wxJ_"
      },
      "id": "S0aMsAL9wxJ_",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Objects Class\n",
        "class QADastset(torch.utils.data.Dataset):\n",
        "  def __init__(self,encodings):\n",
        "    self.encodings = encodings\n",
        "  \n",
        "  def __getitem__(self,idx):\n",
        "    return {key: torch.tensor(val[idx]) for key,val in self.encodings.items()}\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.encodings.input_ids)"
      ],
      "metadata": {
        "id": "POn9tHFyaUyU"
      },
      "id": "POn9tHFyaUyU",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model fine-tuning loop function\n",
        "def fine_tuning_model(model,dataloader,epochs):\n",
        "  # move model to device\n",
        "  model.to(device)\n",
        "\n",
        "  # define optimizer with weight decay to reduce risks of overfitting\n",
        "  opt = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "  for epoch in range(epochs): # per epoch training iteration\n",
        "    model.train()\n",
        "    loop = tqdm(dataloader,leave=True)\n",
        "    for batch in loop: #loop # per batch training iteration\n",
        "      opt.zero_grad()\n",
        "      \n",
        "      # pull tensor batches \n",
        "      input_ids = batch['input_ids'].to(device)\n",
        "      attention_mask = batch['attention_mask'].to(device)\n",
        "      start_positions = batch['start_positions'].to(device)\n",
        "      end_positions = batch['end_positions'].to(device)\n",
        "    \n",
        "      # train model on batch\n",
        "      output = model(input_ids,attention_mask=attention_mask,start_positions=start_positions,end_positions=end_positions)\n",
        "      \n",
        "      # retrive loss      \n",
        "      loss = output[0]\n",
        "      \n",
        "      # backward pass\n",
        "      loss.backward()\n",
        "      \n",
        "      # optimization step\n",
        "      opt.step()\n",
        "\n",
        "      # display results      \n",
        "      loop.set_description(f'Epoch {epoch}')\n",
        "      loop.set_postfix(loss=loss.item())\n",
        "      \n",
        "    return(model)"
      ],
      "metadata": {
        "id": "LsQKh7BerCIE"
      },
      "id": "LsQKh7BerCIE",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-15MZ2XA0Nd",
        "outputId": "a2c0078a-95cd-4ad0-b837-96a80898b6a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForQuestionAnswering: ['vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias']\n",
            "- This IS expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# [M1] DistilRoBERTa (distilbert-base). \n",
        "# M1 tokenizer and model definition\n",
        "from transformers import DistilBertTokenizerFast, DistilBertForQuestionAnswering\n",
        "tokenizer_M1 = DistilBertTokenizerFast.from_pretrained('distilbert-base-cased')\n",
        "M1 = DistilBertForQuestionAnswering.from_pretrained('distilbert-base-cased')\n",
        "\n",
        "# DistillRoberta. Citing:\n",
        "#  https://huggingface.co/distilroberta-base\n",
        "#  @article{Sanh2019DistilBERTAD,\n",
        "#  title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter},\n",
        "#  author={Victor Sanh and Lysandre Debut and Julien Chaumond and Thomas Wolf},\n",
        "#  journal={ArXiv},\n",
        "#  year={2019},\n",
        "#  volume={abs/1910.01108}\n",
        "# }\n",
        "# Reference for code: https://towardsdatascience.com/how-to-fine-tune-a-q-a-transformer-86f91ec92997"
      ],
      "id": "d-15MZ2XA0Nd"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "OGseWtLOvHZj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8821238-3454-4c95-b98d-a60a343c0a1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "# [M2] BERTTiny (bert-tiny)\n",
        "# M2 tokenizer and model definition\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "model_name = \"prajjwal1/bert-tiny\"\n",
        "M2 = AutoModel.from_pretrained(model_name)\n",
        "tokenizer_M2 = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# BERT Tiny model. Citing:\n",
        "# https://huggingface.co/prajjwal1/bert-tiny\n",
        "# @misc{bhargava2021generalization,\n",
        "#      title={Generalization in NLI: Ways (Not) To Go Beyond Simple Heuristics}, \n",
        "#      author={Prajjwal Bhargava and Aleksandr Drozd and Anna Rogers},\n",
        "#      year={2021},\n",
        "#      eprint={2110.01518},\n",
        "#      archivePrefix={arXiv},\n",
        "#      primaryClass={cs.CL}\n",
        "# }\n",
        "# @article{DBLP:journals/corr/abs-1908-08962,\n",
        "#  author    = {Iulia Turc and\n",
        "#               Ming{-}Wei Chang and\n",
        "#               Kenton Lee and\n",
        "#               Kristina Toutanova},\n",
        "#  title     = {Well-Read Students Learn Better: The Impact of Student Initialization\n",
        "#               on Knowledge Distillation},\n",
        "#  journal   = {CoRR},\n",
        "#  volume    = {abs/1908.08962},\n",
        "#  year      = {2019},\n",
        "#  url       = {http://arxiv.org/abs/1908.08962},\n",
        "#  eprinttype = {arXiv},\n",
        "#  eprint    = {1908.08962},\n",
        "#  timestamp = {Thu, 29 Aug 2019 16:32:34 +0200},\n",
        "#  biburl    = {https://dblp.org/rec/journals/corr/abs-1908-08962.bib},\n",
        "#  bibsource = {dblp computer science bibliography, https://dblp.org}\n",
        "# }"
      ],
      "id": "OGseWtLOvHZj"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1e83f28"
      },
      "source": [
        "## [Task 4] Question generation with text passage $P$ and question $Q$\n",
        "\n",
        "We want to define $f_\\theta(P, Q)$. \n",
        "\n",
        "Write your own script to implement $f_\\theta$ for each model: M1 and M2.\n",
        "\n",
        "#### Formulation\n",
        "\n",
        "Consider a dialogue on text passage $P$. \n",
        "\n",
        "For each question $Q_i$ at dialogue turn $i$, your model should take $P$ and $Q_i$ and generate $A_i$."
      ],
      "id": "f1e83f28"
    },
    {
      "cell_type": "code",
      "source": [
        "# M1 Training tokenization\n",
        "#train_encodings_M1 = tokenization(tokenizer_M1,train_story,train_question,train_answer_start,train_answer_end)"
      ],
      "metadata": {
        "id": "fzhCMQVejoXu"
      },
      "id": "fzhCMQVejoXu",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# M1 Validation tokenization\n",
        "val_encodings_M1 = tokenization(tokenizer_M1,val_story,val_question,val_answer_start,val_answer_end)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcUPhy_En0PL",
        "outputId": "86d7b87b-943c-4d23-fcd0-25dbd097e0c6"
      },
      "id": "NcUPhy_En0PL",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q/A pairs tokenized 20415\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# M1 Test tokenization\n",
        "test_encodings_M1 = tokenization(tokenizer_M1,test_story,test_question,test_answer_start,test_answer_end)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYBOtjf3n0GL",
        "outputId": "fc5f4358-b8a8-42e9-edac-cde18589f206"
      },
      "id": "AYBOtjf3n0GL",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q/A pairs tokenized 7028\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# M1 model Datasets initalization\n",
        "#train_dataset_M1 = QADastset(train_encodings_M1) \n",
        "val_dataset_M1 = QADastset(val_encodings_M1) \n",
        "test_dataset_M1 = QADastset(test_encodings_M1)\n",
        "\n",
        "# DataLoaders initialization\n",
        "#train_dataloader_M1 = DataLoader(train_dataset_M1,batch_size=10,shuffle=True) \n",
        "val_dataloader_M1 = DataLoader(val_dataset_M1,batch_size=10,shuffle=False) \n",
        "test_dataloader_M1 = DataLoader(test_dataset_M1,batch_size=10,shuffle=False) "
      ],
      "metadata": {
        "id": "LZ1Z02Q2rxRZ"
      },
      "id": "LZ1Z02Q2rxRZ",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# M1 Model fine tuning\n",
        "M1 = fine_tuning_model(M1,train_dataloader_M1,epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "6dm6ok5btZ88",
        "outputId": "0cb5254a-0912-4f13-e1a9-bf029d59fd29"
      },
      "id": "6dm6ok5btZ88",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-2d9a2d434c8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# M1 Model fine tuning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mM1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfine_tuning_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_dataloader_M1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train_dataloader_M1' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# M2 model Training tokenization\n",
        "#train_encodings_M2 = tokenization(tokenizer_M2,train_story,train_question,train_answer_start,train_answer_end)"
      ],
      "metadata": {
        "id": "0NThIOMjx9RD"
      },
      "id": "0NThIOMjx9RD",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# M2 Model Validation tokenization\n",
        "#val_encodings_M2 = tokenization(tokenizer_M2,val_story,val_question,val_answer_start,val_answer_end)"
      ],
      "metadata": {
        "id": "LrqFlrHIyAHk"
      },
      "id": "LrqFlrHIyAHk",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# M2 Model Test tokenization\n",
        "test_encodings_M2 = tokenization(tokenizer_M2,test_story,test_question,test_answer_start,test_answer_end)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNJoUypjx_6E",
        "outputId": "2c95559c-c332-44e1-96ab-0770ed229e35"
      },
      "id": "kNJoUypjx_6E",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q/A pairs tokenized 7060\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Datasets initalization\n",
        "#train_dataset_M2 = QADastset(train_encodings_M2) \n",
        "#val_dataset_M2 = QADastset(val_encodings_M2) \n",
        "test_dataset_M2 = QADastset(test_encodings_M2)\n",
        "\n",
        "# DataLoaders initialization\n",
        "#train_dataloader_M2 = DataLoader(train_dataset_M2,batch_size=10,shuffle=True) \n",
        "#val_dataloader_M2 = DataLoader(val_dataset_M2,batch_size=10,shuffle=False) \n",
        "test_dataloader_M2 = DataLoader(test_dataset_M2,batch_size=10,shuffle=False) "
      ],
      "metadata": {
        "id": "Tz_spCtByzpc"
      },
      "id": "Tz_spCtByzpc",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# M2 model fine-tuning\n",
        "M2 = fine_tuning_model(M2,train_dataloader_M2,epochs)"
      ],
      "metadata": {
        "id": "BjeQ8evuyrIW"
      },
      "id": "BjeQ8evuyrIW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7311ba86"
      },
      "source": [
        "## [Task 5] Question generation with text passage $P$, question $Q$ and dialogue history $H$\n",
        "\n",
        "We want to define $f_\\theta(P, Q, H)$. Write your own script to implement $f_\\theta$ for each model: M1 and M2.\n",
        "\n",
        "#### Formulation\n",
        "\n",
        "Consider a dialogue on text passage $P$. \n",
        "\n",
        "For each question $Q_i$ at dialogue turn $i$, your model should take $P$, $Q_i$, and $H = \\{ Q_0, A_0, \\dots, Q_{i-1}, A_{i-1} \\}$ to generate $A_i$."
      ],
      "id": "7311ba86"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5ac768c"
      },
      "source": [
        "## [Task 6] Train and evaluate $f_\\theta(P, Q)$ and $f_\\theta(P, Q, H)$\n",
        "\n",
        "Write your own script to train and evaluate your $f_\\theta(P, Q)$ and $f_\\theta(P, Q, H)$ models.\n",
        "\n",
        "### Instructions\n",
        "\n",
        "* Perform multiple train/evaluation seed runs: [42, 2022, 1337].$^1$\n",
        "* Evaluate your models with the following metrics: SQUAD F1-score.$^2$\n",
        "* Fine-tune each transformer-based models for **3 epochs**.\n",
        "* Report evaluation SQUAD F1-score computed on the validation and test sets.\n",
        "\n",
        "$^1$ Remember what we said about code reproducibility in Tutorial 2!\n",
        "\n",
        "$^2$ You can use ```allennlp``` python package for a quick implementation of SQUAD F1-score: ```from allennlp_models.rc.tools import squad```. "
      ],
      "id": "b5ac768c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92c7e98f"
      },
      "source": [
        "## [Task 7] Error Analysis\n",
        "\n",
        "Perform a simple and short error analysis as follows:\n",
        "* Group dialogues by ```source``` and report the worst 5 model errors for each source (w.r.t. SQUAD F1-score).\n",
        "* Inspect observed results and try to provide some comments (e.g., do the models make errors when faced with a particular question type?)$^1$\n",
        "\n",
        "$^1$ Check the [paper](https://arxiv.org/pdf/1808.07042.pdf) for some valuable information about question/answer types (e.g., Table 6, Table 8) "
      ],
      "id": "92c7e98f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1814004"
      },
      "source": [
        "# Assignment Evaluation\n",
        "\n",
        "The following assignment points will be awarded for each task as follows:\n",
        "\n",
        "* Task 1, Pre-processing $\\rightarrow$ 0.5 points.\n",
        "* Task 2, Dataset Splitting $\\rightarrow$ 0.5 points.\n",
        "* Task 3 and 4, Models Definition $\\rightarrow$ 1.0 points.\n",
        "* Task 5 and 6, Models Training and Evaluation $\\rightarrow$ 2.0 points.\n",
        "* Task 7, Analysis $\\rightarrow$ 1.0 points.\n",
        "* Report $\\rightarrow$ 1.0 points.\n",
        "\n",
        "**Total** = 6 points <br>\n",
        "\n",
        "We may award an additional 0.5 points for outstanding submissions. \n",
        " \n",
        "**Speed Bonus** = 0.5 extra points <br>"
      ],
      "id": "f1814004"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20a1b2b9"
      },
      "source": [
        "# Report\n",
        "\n",
        "We apply the rules described in Assignment 1 regarding the report.\n",
        "* Write a clear and concise report following the given overleaf template (**max 2 pages**).\n",
        "* Report validation and test results in a table.$^1$\n",
        "* **Avoid reporting** code snippets or copy-paste terminal outputs $\\rightarrow$ **Provide a clean schema** of what you want to show"
      ],
      "id": "20a1b2b9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0967c209"
      },
      "source": [
        "# Comments and Organization\n",
        "\n",
        "Remember to properly comment your code (it is not necessary to comment each single line) and don't forget to describe your work!\n",
        "\n",
        "Structure your code for readability and maintenance. If you work with Colab, use sections. \n",
        "\n",
        "This allows you to build clean and modular code, as well as easy to read and to debug (notebooks can be quite tricky time to time)."
      ],
      "id": "0967c209"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23929660"
      },
      "source": [
        "# FAQ (READ THIS!)\n",
        "\n",
        "---\n",
        "\n",
        "**Question**: Does Task 3 also include data tokenization and conversion step?\n",
        "\n",
        "**Answer:** Yes! These steps are usually straightforward since ```transformers``` also offers a specific tokenizer for each model.\n",
        "\n",
        "**Example**: \n",
        "\n",
        "```\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "encoded_text = tokenizer(text)\n",
        "%% Alternatively\n",
        "inputs = tokenizer.tokenize(text, add_special_tokens=True, max_length=min(max_length, 512))\n",
        "input_ids, attention_mask = inputs['input_ids'], inputs['attention_mask']\n",
        "```\n",
        "\n",
        "**Suggestion**: Hugginface's documentation is full of tutorials and user-friendly APIs.\n",
        "\n",
        "---\n",
        "---\n",
        "\n",
        "**Question**: I'm hitting **out of memory error** when training my models, do you have any suggestions?\n",
        "\n",
        "**Answer**: Here are some common workarounds:\n",
        "\n",
        "1. Try decreasing the mini-batch size\n",
        "2. Try applying a different padding strategy (if you are applying padding): e.g. use quantiles instead of maximum sequence length\n",
        "\n",
        "---\n",
        "---"
      ],
      "id": "23929660"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9c56a612"
      },
      "source": [
        "# Contact\n",
        "\n",
        "For any doubt, question, issue or help, you can always contact us at the following email addresses:\n",
        "\n",
        "Teaching Assistants:\n",
        "\n",
        "* Andrea Galassi -> a.galassi@unibo.it\n",
        "* Federico Ruggeri -> federico.ruggeri6@unibo.it\n",
        "\n",
        "Professor:\n",
        "\n",
        "* Paolo Torroni -> p.torroni@unibo.it"
      ],
      "id": "9c56a612"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54bac4b9"
      },
      "source": [
        "# The End!\n",
        "\n",
        "Questions?"
      ],
      "id": "54bac4b9"
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "collapsed_sections": [
        "bd3f451b",
        "47c07553",
        "b4907f8d",
        "9b3760b5",
        "bfb6c37e",
        "daa786e2",
        "d26d68b7",
        "72c7558c",
        "7311ba86",
        "b5ac768c",
        "92c7e98f",
        "f1814004",
        "20a1b2b9",
        "0967c209",
        "23929660",
        "9c56a612",
        "54bac4b9"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}